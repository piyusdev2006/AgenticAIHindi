{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/piyusdev2006/AgenticAIHindi/blob/main/M1_Assignment_Stock_Price_Prediction_with_LLM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3XRCzVcg8qq6"
      },
      "source": [
        "# Module 1 No Code/Low Code Assignment: Stock Price Prediction with LLM (Using Gemini in Colab)\n",
        "\n",
        "This assignment explores how large language models (LLMs) can perform complex tasks that previously required coding. Instead of manually writing code, we will interact with Google's Gemini (Click on the Gemini icon on the top right corner) in Google Colab to:\n",
        "\n",
        "- Load and analyze stock price data.\n",
        "- Engineer relevant features for prediction.\n",
        "- Build and evaluate models such as regression and random forest.\n",
        "- Discuss potential trading strategies based on predictions.\n",
        "\n",
        "**Note**: While this notebook contains example code, students are encouraged to use LLMs to generate code snippets and explanations, managing interactions within the LLM's context window.\n",
        "\n",
        "## Task Breakdown\n",
        "\n",
        "### Step 1: Data Exploration\n",
        "- **Prompt the LLM**: Load historical stock price data for Apple Inc. (AAPL) from 2020-01-01 to 2023-01-01 using Yahoo Finance.\n",
        "- **Key Considerations**: Ensure the model retains context while summarizing key statistics.\n",
        "\n",
        "### Step 2: Feature Engineering\n",
        "- **Prompt the LLM**: Generate meaningful features such as moving averages, technical indicators, and volatility measures.\n",
        "- **Managing Context**: If the LLM forgets prior outputs, remind it by reintroducing key statistics.\n",
        "\n",
        "### Step 3: Model Building\n",
        "- **Prompt the LLM**: Train a model (regression for price prediction, random forest for trend classification).\n",
        "- **Split Ratio Consideration**: Explain the importance of train-test split (e.g., 70/30) and verify the LLM respects it.\n",
        "\n",
        "### Step 4: Model Evaluation & Prediction\n",
        "- **Prompt the LLM**: Use the trained model to predict stock prices for 2023-2024.\n",
        "- **Analyze Performance**: Interpret accuracy, R² scores, and classification reports.\n",
        "\n",
        "### Step 5: Strategy Discussion\n",
        "- **Prompt the LLM**: Based on model performance, discuss possible trading strategies.\n",
        "- **Critical Thinking**: Evaluate whether the model is truly useful for financial decision-making.\n",
        "\n",
        "---\n",
        "\n",
        "Throughout the assignment, keep in mind that LLMs have a limited context window. If necessary, break down tasks into smaller chunks and reintroduce critical information.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_csYjq8h7yt"
      },
      "source": [
        "## Using Gemini in Colab\n",
        "\n",
        "To use Gemini directly in your browser within Google Colab:\n",
        "\n",
        "1. **Create a new code cell** by clicking the `+ Code` button.\n",
        "2. In the newly created cell, you will see a placeholder text: **\"Start coding or generate with AI\"**.\n",
        "3. Click on **\"Generate\"** and enter your prompt, such as:\n",
        "   > \"Load historical stock price data for Apple Inc. (AAPL) from 2020-01-01 to 2023-01-01 using Yahoo Finance and summarize its key statistics.\"\n",
        "4. Gemini will generate code based on your prompt. You can then review, modify, and run it within the notebook.\n",
        "5. If the model loses context, you may need to remind it of previous responses or break down tasks into smaller steps.\n",
        "\n",
        "This method allows you to interactively generate and refine code without manually writing every line.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "iMgjTlOjk05n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0566dc9e-9a87-4f83-9c57-ddc144bc1c7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.12/dist-packages (0.2.65)\n",
            "Requirement already satisfied: pandas>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from yfinance) (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.12/dist-packages (from yfinance) (2.0.2)\n",
            "Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.12/dist-packages (from yfinance) (2.32.4)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.12/dist-packages (from yfinance) (0.0.12)\n",
            "Requirement already satisfied: platformdirs>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from yfinance) (4.4.0)\n",
            "Requirement already satisfied: pytz>=2022.5 in /usr/local/lib/python3.12/dist-packages (from yfinance) (2025.2)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.12/dist-packages (from yfinance) (2.4.6)\n",
            "Requirement already satisfied: peewee>=3.16.2 in /usr/local/lib/python3.12/dist-packages (from yfinance) (3.18.2)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.12/dist-packages (from yfinance) (4.13.5)\n",
            "Requirement already satisfied: curl_cffi>=0.7 in /usr/local/lib/python3.12/dist-packages (from yfinance) (0.13.0)\n",
            "Requirement already satisfied: protobuf>=3.19.0 in /usr/local/lib/python3.12/dist-packages (from yfinance) (5.29.5)\n",
            "Requirement already satisfied: websockets>=13.0 in /usr/local/lib/python3.12/dist-packages (from yfinance) (15.0.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (4.15.0)\n",
            "Requirement already satisfied: cffi>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from curl_cffi>=0.7->yfinance) (1.17.1)\n",
            "Requirement already satisfied: certifi>=2024.2.2 in /usr/local/lib/python3.12/dist-packages (from curl_cffi>=0.7->yfinance) (2025.8.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.3.0->yfinance) (2.9.0.post0)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.3.0->yfinance) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31->yfinance) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31->yfinance) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31->yfinance) (2.5.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12.0->curl_cffi>=0.7->yfinance) (2.22)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=1.3.0->yfinance) (1.17.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1433581267.py:9: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  data = yf.download(\"AAPL\", start=\"2020-01-01\", end=\"2023-01-01\")\n",
            "\r[*********************100%***********************]  1 of 1 completed"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Price        Close        High         Low        Open        Volume\n",
            "Ticker        AAPL        AAPL        AAPL        AAPL          AAPL\n",
            "count   756.000000  756.000000  756.000000  756.000000  7.560000e+02\n",
            "mean    127.488414  129.035076  125.828629  127.410552  1.120920e+08\n",
            "std      30.386976   30.664098   30.105383   30.415044  5.602586e+07\n",
            "min      54.316936   55.316755   51.470001   55.215079  3.519590e+07\n",
            "25%     112.581745  114.075468  111.125710  112.761702  7.636470e+07\n",
            "50%     132.859993  133.991789  130.902093  132.681725  9.493580e+07\n",
            "75%     148.053505  149.219245  146.111074  147.421478  1.296327e+08\n",
            "max     178.443115  179.354886  175.609740  179.050963  4.265100e+08\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# prompt: Load historical stock price data for Apple Inc. (AAPL) from 2020-01-01 to 2023-01-01 using Yahoo Finance and summarize its key statistics.\n",
        "\n",
        "!pip install yfinance\n",
        "\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "\n",
        "# Download historical data for AAPL\n",
        "data = yf.download(\"AAPL\", start=\"2020-01-01\", end=\"2023-01-01\")\n",
        "\n",
        "# Display summary statistics\n",
        "print(data.describe())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qKaqonJh7rMO",
        "outputId": "a58a03ba-04fc-46f9-8fdb-b6209d73461a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.12/dist-packages (0.2.65)\n",
            "Requirement already satisfied: pandas>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from yfinance) (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.12/dist-packages (from yfinance) (2.0.2)\n",
            "Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.12/dist-packages (from yfinance) (2.32.4)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.12/dist-packages (from yfinance) (0.0.12)\n",
            "Requirement already satisfied: platformdirs>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from yfinance) (4.4.0)\n",
            "Requirement already satisfied: pytz>=2022.5 in /usr/local/lib/python3.12/dist-packages (from yfinance) (2025.2)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.12/dist-packages (from yfinance) (2.4.6)\n",
            "Requirement already satisfied: peewee>=3.16.2 in /usr/local/lib/python3.12/dist-packages (from yfinance) (3.18.2)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.12/dist-packages (from yfinance) (4.13.5)\n",
            "Requirement already satisfied: curl_cffi>=0.7 in /usr/local/lib/python3.12/dist-packages (from yfinance) (0.13.0)\n",
            "Requirement already satisfied: protobuf>=3.19.0 in /usr/local/lib/python3.12/dist-packages (from yfinance) (5.29.5)\n",
            "Requirement already satisfied: websockets>=13.0 in /usr/local/lib/python3.12/dist-packages (from yfinance) (15.0.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (4.15.0)\n",
            "Requirement already satisfied: cffi>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from curl_cffi>=0.7->yfinance) (1.17.1)\n",
            "Requirement already satisfied: certifi>=2024.2.2 in /usr/local/lib/python3.12/dist-packages (from curl_cffi>=0.7->yfinance) (2025.8.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.3.0->yfinance) (2.9.0.post0)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.3.0->yfinance) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31->yfinance) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31->yfinance) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31->yfinance) (2.5.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12.0->curl_cffi>=0.7->yfinance) (2.22)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=1.3.0->yfinance) (1.17.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-730687086.py:9: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  data = yf.download(\"AAPL\", start=\"2020-01-01\", end=\"2023-01-01\")\n",
            "\r[*********************100%***********************]  1 of 1 completed"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Price        Close        High         Low        Open        Volume\n",
            "Ticker        AAPL        AAPL        AAPL        AAPL          AAPL\n",
            "count   756.000000  756.000000  756.000000  756.000000  7.560000e+02\n",
            "mean    127.488414  129.035076  125.828629  127.410552  1.120920e+08\n",
            "std      30.386976   30.664098   30.105383   30.415044  5.602586e+07\n",
            "min      54.316936   55.316755   51.470001   55.215079  3.519590e+07\n",
            "25%     112.581745  114.075468  111.125710  112.761702  7.636470e+07\n",
            "50%     132.859993  133.991789  130.902093  132.681725  9.493580e+07\n",
            "75%     148.053505  149.219245  146.111074  147.421478  1.296327e+08\n",
            "max     178.443115  179.354886  175.609740  179.050963  4.265100e+08\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# prompt: Load historical stock price data for Apple Inc. (AAPL) from 2020-01-01 to 2023-01-01 using Yahoo Finance and summarize its key statistics.\n",
        "\n",
        "!pip install yfinance\n",
        "\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "\n",
        "# Download historical data for AAPL from 2020-01-01 to 2023-01-01\n",
        "data = yf.download(\"AAPL\", start=\"2020-01-01\", end=\"2023-01-01\")\n",
        "\n",
        "# Summarize key statistics\n",
        "print(data.describe())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tEuXvSCP6QWj",
        "outputId": "751d4d13-5c73-4adf-fac8-10fa71c7bce9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3699561310.py:6: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  data = yf.download(\"AAPL\", start=\"2020-01-01\", end=\"2023-01-01\")\n",
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Price        Close        High         Low        Open        Volume\n",
            "Ticker        AAPL        AAPL        AAPL        AAPL          AAPL\n",
            "count   756.000000  756.000000  756.000000  756.000000  7.560000e+02\n",
            "mean    127.488414  129.035076  125.828629  127.410552  1.120920e+08\n",
            "std      30.386976   30.664098   30.105383   30.415044  5.602586e+07\n",
            "min      54.316936   55.316755   51.470001   55.215079  3.519590e+07\n",
            "25%     112.581745  114.075468  111.125710  112.761702  7.636470e+07\n",
            "50%     132.859993  133.991789  130.902093  132.681725  9.493580e+07\n",
            "75%     148.053505  149.219245  146.111074  147.421478  1.296327e+08\n",
            "max     178.443115  179.354886  175.609740  179.050963  4.265100e+08\n"
          ]
        }
      ],
      "source": [
        "# Prompt: Load historical stock price data for Apple Inc. (AAPL) from 2020-01-01 to 2023-01-01\n",
        "# using Yahoo Finance and summarize its key statistics.\n",
        "\n",
        "import yfinance as yf\n",
        "\n",
        "data = yf.download(\"AAPL\", start=\"2020-01-01\", end=\"2023-01-01\")\n",
        "\n",
        "# Summarize key statistics\n",
        "print(data.describe())\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mO9zmOSrj7b2"
      },
      "source": [
        "## Now try doing step 2 - step 5 by yourself\n",
        "\n",
        "The sample prompts and LLM responses are listed below for your reference."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KSb-lVTs67ir"
      },
      "source": [
        "# Sample Prompts and LLM Responses\n",
        "---\n",
        "\n",
        "## Step 1: Data Exploration\n",
        "\n",
        "### Prompt:\n",
        "> Load historical stock price data for Apple Inc. (AAPL) from 2020-01-01 to 2023-01-01 from Yahoo Finance, keep it in memory and summarize its key statistics.\n",
        "\n",
        "### LLM Response:\n",
        "- **Highest Closing Price:** \\$182.01 on January 3, 2022\n",
        "- **Lowest Closing Price:** \\$56.01 on March 23, 2020\n",
        "- **Average Closing Price:** \\$126.69\n",
        "- **Total Trading Days:** 756\n",
        "\n",
        "---\n",
        "\n",
        "## Step 2: Feature Engineering\n",
        "\n",
        "### Prompt:\n",
        "> Suggest some features that might help improve a stock price prediction model.\n",
        "\n",
        "### LLM Response:\n",
        "1. **Historical Prices**: Include past closing, opening, high, and low prices.\n",
        "2. **Volume**: Daily trading volumes.\n",
        "3. **Moving Averages**: Simple and exponential moving averages (e.g., 5-day, 10-day, 50-day).\n",
        "4. **Technical Indicators**: RSI, MACD, Bollinger Bands, etc.\n",
        "5. **Volatility**: Historical volatility, Average True Range (ATR).\n",
        "6. **Sentiment Analysis**: News articles, social media sentiment.\n",
        "7. **Economic Indicators**: Interest rates, inflation rates, GDP growth.\n",
        "8. **Time-based Features**: Day of the week, month, year.\n",
        "9. **Sector Performance**: Comparison with industry and sector indices.\n",
        "10. **External Events**: Major geopolitical events, earnings reports.\n",
        "\n",
        "---\n",
        "\n",
        "## Step 3.1: Model Building - Linear Regression\n",
        "\n",
        "### Prompt:\n",
        "> Adopt the first four kinds of features and train a regression model to predict tomorrow's stock price. Split your training and testing data by a 70/30 ratio and report your performance metric.\n",
        "\n",
        "### LLM Response:\n",
        "- **Mean Squared Error (MSE):** 859.04\n",
        "- **R-squared (R²) Score:** -0.009\n",
        "\n",
        "These metrics indicate that the model is not performing well, as an R² score close to zero or negative suggests that the model does not explain the variability in the target variable better than a simple mean of the target variable. This outcome suggests that the chosen features and model might need adjustments or improvements to enhance prediction accuracy. ​​\n",
        "\n",
        "---\n",
        "(It might be too hard to predict the exact price but how about ups and downs?)\n",
        "# Step 3.2: Model Building - Random Forest Classification\n",
        "\n",
        "### Prompt:\n",
        "> Create a binary target variable based on historical prices (1 if the close price increase tomorrow, 0 other), and train a Random Forest model using the same train/test split ratio. Report feature importance and performance metrics.\n",
        "\n",
        "### LLM Response:\n",
        "- **Accuracy:** 71.82%\n",
        "- **Confusion Matrix:** [[84, 26],\n",
        " [36, 74]]\n",
        "- **Classification Report:**\n",
        "\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "         0       0.70      0.76      0.73       110\n",
        "         1       0.74      0.67      0.70       110\n",
        "        accuracy                     0.72       220\n",
        "        macro avg    0.72      0.72      0.72       220\n",
        "        weighted avg  0.72      0.72      0.72       220\n",
        "\n",
        "\n",
        "\n",
        "- **Feature Importance:** The most important feature for predicting whether the price will increase or decrease the next day is the closing price, followed by the 5-day moving average (MA_5). The model achieved an accuracy of approximately 71.82%, indicating a reasonable performance for this classification task.\n",
        "         Feature\tImportance\n",
        "         Open\t   0.0900\n",
        "         High\t   0.0883\n",
        "         Low\t   0.0980\n",
        "         Close\t   0.3087\n",
        "         Volume\t    0.0982\n",
        "         MA_5\t   0.1242\n",
        "         MA_10\t   0.0974\n",
        "         MA_50\t   0.0951\n",
        "\n",
        "---\n",
        "\n",
        "## Step 4: Model Evaluation & Prediction\n",
        "### Prompt:\n",
        "> Use this model to predict stock price increase/decrease for period starting from 2023-01-01 to 2024-01-01. Report your performance metrics.\n",
        "\n",
        "### LLM Response:\n",
        "The Random Forest classifier's performance on the new test data from 2023-01-01 to 2024-01-01 is as follows:\n",
        "- **Accuracy:** 60.85%\n",
        "- **Confusion Matrix:** [[105,   0],\n",
        " [ 83,  24]]\n",
        "- **Classification Report:**\n",
        "\n",
        "            precision    recall  f1-score   support\n",
        "\n",
        "       0       0.56      1.00      0.72       105\n",
        "       1       1.00      0.22      0.37       107\n",
        "\n",
        "        accuracy                   0.61       212\n",
        "        macro avg  0.78     0.61       0.54       212\n",
        "        weighted avg 0.78    0.61        0.54       212\n",
        "\n",
        "---\n",
        "## Step 5: Strategy Discussion\n",
        "### Prompt:\n",
        "> What do you think about the performance of the model and what trading strategies could I build with this model?\n",
        "\n",
        "### LLM Response:\n",
        "- The model shows a moderate performance with an accuracy of approximately 60.85%. However, the precision and recall metrics indicate that while the model is good at identifying days when the stock price does not increase (class 0), it struggles significantly to identify days when the stock price does increase (class 1). This suggests a need for further feature engineering or model tuning to improve the prediction performance for this specific classification task.\n",
        "- Potential Trading Strategies\n",
        "Given the model's performance, potential trading strategies could be formulated as follows:\n",
        "\n",
        "#### Conservative Strategy:\n",
        "\n",
        "- **Focus**: Only trade on days when the model predicts a price increase with high confidence.\n",
        "- **Action**: Buy stocks when the model predicts an increase (class 1).\n",
        "- **Risk Management**: Since the model has a high precision for the no-increase class (class 0), it might be more reliable to stay out of the market when the model predicts no increase.\n",
        "\n",
        "#### Contrarian Strategy:\n",
        "\n",
        "- **Focus**: Take advantage of the model's high recall for no price increase predictions (class 0).\n",
        "- **Action**: Sell short or avoid buying stocks on days when the model predicts no increase.\n",
        "- **Risk Management**: This strategy assumes that the model’s predictions of no price increase are more reliable. It requires a careful assessment of market conditions to avoid false signals.\n",
        "\n",
        "#### Hybrid Strategy:\n",
        "\n",
        "- **Combine**: Use both conservative and contrarian strategies based on confidence thresholds.\n",
        "- **Action**: Set a higher threshold for buying (only buy when the predicted probability of price increase is significantly high) and a lower threshold for selling or staying out of the market.\n",
        "- **Risk Management**: Adjust thresholds dynamically based on recent model performance and market volatility.\n",
        "\n",
        "\n",
        "---\n",
        "## Conclusion\n",
        "\n",
        "Through this assignment, we have explored how LLMs can assist in complex machine learning tasks without requiring extensive coding knowledge. Key takeaways:\n",
        "\n",
        "- **Context Management**: LLMs have limited memory, so breaking tasks into smaller steps and reinforcing context is crucial.\n",
        "- **Feature Engineering with LLMs**: The model can suggest features but needs guidance on financial relevance.\n",
        "- **Modeling with LLMs**: LLMs can write and refine code, but human judgment is necessary to validate results.\n",
        "- **Real-world Limitations**: Stock price prediction remains challenging; models should be used critically and not solely relied upon for trading decisions.\n",
        "\n",
        "Next Steps:\n",
        "- Experiment with different LLMs and compare outputs.\n",
        "- Try refining feature engineering techniques.\n",
        "- Test alternative modeling approaches, such as deep learning or ensemble methods.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "WG8HlPU6N8BB"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6072af0"
      },
      "source": [
        "# Task\n",
        "Analyze historical stock price data to predict future price movements using regression and classification models, and discuss potential trading strategies based on the classification model's performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "515b8291"
      },
      "source": [
        "## Feature engineering\n",
        "\n",
        "### Subtask:\n",
        "Generate meaningful features such as moving averages, technical indicators, and volatility measures based on the loaded stock price data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48a65b53"
      },
      "source": [
        "**Reasoning**:\n",
        "Calculate moving averages, daily range, and daily return, then remove rows with NaN values.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b78e0fbe"
      },
      "source": [
        "data['MA_5'] = data['Close'].rolling(window=5).mean()\n",
        "data['MA_10'] = data['Close'].rolling(window=10).mean()\n",
        "data['MA_50'] = data['Close'].rolling(window=50).mean()\n",
        "data['Daily_Range'] = data['High'] - data['Low']\n",
        "data['Daily_Return'] = data['Close'].pct_change()\n",
        "data.dropna(inplace=True)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "4Azv7KJQkStv"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1f7b2759"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous code block failed because the `data` DataFrame was not defined. I need to redefine the data DataFrame by loading the data again.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4H7sRd3JO3qK",
        "outputId": "a3fe2818-5a59-44fa-bf36-7f4c1ae24d27"
      },
      "source": [
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "\n",
        "data = yf.download(\"AAPL\", start=\"2020-01-01\", end=\"2023-01-01\")\n",
        "data['MA_5'] = data['Close'].rolling(window=5).mean()\n",
        "data['MA_10'] = data['Close'].rolling(window=10).mean()\n",
        "data['MA_50'] = data['Close'].rolling(window=50).mean()\n",
        "data['Daily_Range'] = data['High'] - data['Low']\n",
        "data['Daily_Return'] = data['Close'].pct_change()\n",
        "data.dropna(inplace=True)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1572279735.py:4: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  data = yf.download(\"AAPL\", start=\"2020-01-01\", end=\"2023-01-01\")\n",
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8d6d533e"
      },
      "source": [
        "## Data preparation for modeling\n",
        "\n",
        "### Subtask:\n",
        "Split the data into training and testing sets (70/30 ratio) for both regression and classification tasks.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dd6befe9"
      },
      "source": [
        "**Reasoning**:\n",
        "Define features and target variables for regression and classification, then split the data into training and testing sets for both tasks.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "850c99be",
        "outputId": "a371de99-044a-4b53-d6d3-57053b18fa66"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "\n",
        "X = data[['Open', 'High', 'Low', 'Close', 'Volume', 'MA_5', 'MA_10', 'MA_50', 'Daily_Range', 'Daily_Return']]\n",
        "\n",
        "# Create target variables\n",
        "data['Price_Increase'] = (data['Close'].shift(-1) > data['Close']).astype(int)\n",
        "y_regression = data['Close'].shift(-1)\n",
        "y_classification = data['Price_Increase']\n",
        "\n",
        "\n",
        "# Combine features and targets into a single DataFrame and drop rows with NaN values\n",
        "combined_data = pd.concat([X, y_regression.rename('y_regression'), y_classification.rename('y_classification')], axis=1).dropna()\n",
        "\n",
        "X_cleaned = combined_data[X.columns]\n",
        "y_regression_cleaned = combined_data['y_regression']\n",
        "y_classification_cleaned = combined_data['y_classification']\n",
        "\n",
        "\n",
        "# Split the data - ensure y_regression_cleaned is 1D for train_test_split\n",
        "X_train_regression, X_test_regression, y_train_regression, y_test_regression = train_test_split(\n",
        "    X_cleaned, y_regression_cleaned.squeeze(), test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "X_train_classification, X_test_classification, y_train_classification, y_test_classification = train_test_split(\n",
        "    X_cleaned, y_classification_cleaned, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "print(\"Regression Data Shapes:\")\n",
        "print(\"X_train_regression:\", X_train_regression.shape)\n",
        "print(\"X_test_regression:\", X_test_regression.shape)\n",
        "print(\"y_train_regression:\", y_train_regression.shape)\n",
        "print(\"y_test_regression:\", y_test_regression.shape)\n",
        "\n",
        "print(\"\\nClassification Data Shapes:\")\n",
        "print(\"X_train_classification:\", X_train_classification.shape)\n",
        "print(\"X_test_classification:\", X_test_classification.shape)\n",
        "print(\"y_train_classification:\", y_train_classification.shape)\n",
        "print(\"y_test_classification:\", y_test_classification.shape)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "'str' object is not callable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3805666661.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Combine features and targets into a single DataFrame and drop rows with NaN values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mcombined_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_regression\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'y_regression'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_classification\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'y_classification'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mX_cleaned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcombined_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mrename\u001b[0;34m(self, mapper, index, columns, axis, copy, inplace, level, errors)\u001b[0m\n\u001b[1;32m   5765\u001b[0m         \u001b[0;36m4\u001b[0m  \u001b[0;36m3\u001b[0m  \u001b[0;36m6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5766\u001b[0m         \"\"\"\n\u001b[0;32m-> 5767\u001b[0;31m         return super()._rename(\n\u001b[0m\u001b[1;32m   5768\u001b[0m             \u001b[0mmapper\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmapper\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5769\u001b[0m             \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_rename\u001b[0;34m(self, mapper, index, columns, axis, copy, inplace, level, errors)\u001b[0m\n\u001b[1;32m   1130\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{missing_labels} not found in axis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1132\u001b[0;31m             \u001b[0mnew_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1133\u001b[0m             \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_axis_nocheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis_no\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m             \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_transform_index\u001b[0;34m(self, func, level)\u001b[0m\n\u001b[1;32m   6535\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6536\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6537\u001b[0;31m             \u001b[0mitems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6538\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtupleize_cols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'str' object is not callable"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3a68721"
      },
      "source": [
        "**Reasoning**:\n",
        "The error indicates that the number of samples in the features (X) and the classification target (y_classification) are inconsistent. This is because dropping the last row from X was done after creating y_classification. The code needs to be fixed to ensure that X and y_classification have the same number of samples before splitting.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R6tmmUMCO_rS",
        "outputId": "b0fc4237-6932-4f07-c504-edcb261ee686"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "\n",
        "X = data[['Open', 'High', 'Low', 'Close', 'Volume', 'MA_5', 'MA_10', 'MA_50', 'Daily_Range', 'Daily_Return']]\n",
        "\n",
        "# Create target variables\n",
        "data['Price_Increase'] = (data['Close'].shift(-1) > data['Close']).astype(int)\n",
        "y_regression = data['Close'].shift(-1)\n",
        "y_classification = data['Price_Increase']\n",
        "\n",
        "# Drop the last row from X, y_regression, and y_classification to align them\n",
        "X = X.iloc[:-1]\n",
        "y_regression = y_regression.iloc[:-1]\n",
        "y_classification = y_classification.iloc[:-1]\n",
        "\n",
        "# Now split the data\n",
        "X_train_regression, X_test_regression, y_train_regression, y_test_regression = train_test_split(\n",
        "    X, y_regression, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "X_train_classification, X_test_classification, y_train_classification, y_test_classification = train_test_split(\n",
        "    X, y_classification, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "print(\"Regression Data Shapes:\")\n",
        "print(\"X_train_regression:\", X_train_regression.shape)\n",
        "print(\"X_test_regression:\", X_test_regression.shape)\n",
        "print(\"y_train_regression:\", y_train_regression.shape)\n",
        "print(\"y_test_regression:\", y_test_regression.shape)\n",
        "\n",
        "print(\"\\nClassification Data Shapes:\")\n",
        "print(\"X_train_classification:\", X_train_classification.shape)\n",
        "print(\"X_test_classification:\", X_test_classification.shape)\n",
        "print(\"y_train_classification:\", y_train_classification.shape)\n",
        "print(\"y_test_classification:\", y_test_classification.shape)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Regression Data Shapes:\n",
            "X_train_regression: (494, 10)\n",
            "X_test_regression: (212, 10)\n",
            "y_train_regression: (494, 1)\n",
            "y_test_regression: (212, 1)\n",
            "\n",
            "Classification Data Shapes:\n",
            "X_train_classification: (494, 10)\n",
            "X_test_classification: (212, 10)\n",
            "y_train_classification: (494,)\n",
            "y_test_classification: (212,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80bcb52f"
      },
      "source": [
        "## Model building (regression)\n",
        "\n",
        "### Subtask:\n",
        "Train a linear regression model to predict tomorrow's stock price using the engineered features.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f538c442"
      },
      "source": [
        "**Reasoning**:\n",
        "Train a linear regression model using the training data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "c3d73686",
        "outputId": "517ecfd0-4daf-4254-d5f0-f0cda5cd0f33"
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "regression_model = LinearRegression()\n",
        "regression_model.fit(X_train_regression, y_train_regression)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression()"
            ],
            "text/html": [
              "<style>#sk-container-id-5 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-5 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-5 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-5 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-5 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-5 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-5 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-5 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-5 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-5 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-5 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-5 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-5 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-5 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-5 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-5 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-5 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-5 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-5 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-5 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-5 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-5 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-5 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-5 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-5 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-5 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-5 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-5 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-5 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-5 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-5 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-5 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-5 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-5 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-5 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-5 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-5 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LinearRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LinearRegression.html\">?<span>Documentation for LinearRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LinearRegression()</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9708c85"
      },
      "source": [
        "## Model evaluation (regression)\n",
        "\n",
        "### Subtask:\n",
        "Evaluate the performance of the regression model using appropriate metrics like Mean Squared Error (MSE) and R-squared (R²).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1abeccbe"
      },
      "source": [
        "**Reasoning**:\n",
        "Evaluate the performance of the trained regression model using Mean Squared Error and R-squared.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53f5ac89",
        "outputId": "30f44439-70e1-4c6d-e7f8-c3f5c43e2c98"
      },
      "source": [
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "y_pred_regression = regression_model.predict(X_test_regression)\n",
        "\n",
        "mse = mean_squared_error(y_test_regression, y_pred_regression)\n",
        "r2 = r2_score(y_test_regression, y_pred_regression)\n",
        "\n",
        "print(f\"Mean Squared Error (MSE): {mse}\")\n",
        "print(f\"R-squared (R²): {r2}\")"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error (MSE): 6.781462881031935\n",
            "R-squared (R²): 0.9914986692076418\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13aab6f5"
      },
      "source": [
        "## Model building (classification)\n",
        "\n",
        "### Subtask:\n",
        "Create a binary target variable for price increase/decrease and train a Random Forest classifier using the engineered features.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7dc6fb47"
      },
      "source": [
        "**Reasoning**:\n",
        "Import the necessary classifier and train the model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "21cb861d",
        "outputId": "f755bbe7-6c3d-4245-9d98-7ce1befe5bbe"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "# The data has already been split into X_train_classification, X_test_classification, y_train_classification, and y_test_classification in the previous step (cell 850c99be).\n",
        "\n",
        "classification_model = RandomForestClassifier(random_state=42)\n",
        "classification_model.fit(X_train_classification, y_train_classification)"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Input y contains NaN.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3721588395.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mclassification_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mclassification_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_classification\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_classification\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    358\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sparse multilabel-indicator for y is not supported.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m         X, y = validate_data(\n\u001b[0m\u001b[1;32m    361\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mvalidate_data\u001b[0;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[1;32m   2959\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2960\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2961\u001b[0;31m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2962\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2963\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1385\u001b[0m     )\n\u001b[1;32m   1386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1387\u001b[0;31m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmulti_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_numeric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_numeric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1389\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_check_y\u001b[0;34m(y, multi_output, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1395\u001b[0m     \u001b[0;34m\"\"\"Isolated part of check_X_y dedicated to y validation\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1396\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1397\u001b[0;31m         y = check_array(\n\u001b[0m\u001b[1;32m   1398\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1399\u001b[0m             \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1106\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mensure_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1107\u001b[0;31m             _assert_all_finite(\n\u001b[0m\u001b[1;32m   1108\u001b[0m                 \u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m                 \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m     _assert_all_finite_element_wise(\n\u001b[0m\u001b[1;32m    121\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite_element_wise\u001b[0;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    167\u001b[0m                 \u001b[0;34m\"#estimators-that-handle-nan-values\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m             )\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input y contains NaN."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81e4bca2"
      },
      "source": [
        "## Model evaluation (classification)\n",
        "\n",
        "### Subtask:\n",
        "Evaluate the performance of the classification model using metrics like accuracy, confusion matrix, and classification report. Report feature importance for the Random Forest model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a88b7d24"
      },
      "source": [
        "**Reasoning**:\n",
        "Import necessary libraries for classification evaluation and feature importance, then perform predictions and evaluate the model. Finally, display the feature importances.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "45e79d6c",
        "outputId": "2818bbeb-3c4c-4ce4-e984-47c7d5d87530"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming classification_model, X_test_classification, and y_test_classification are defined from previous steps\n",
        "\n",
        "y_pred_classification = classification_model.predict(X_test_classification)\n",
        "\n",
        "accuracy = accuracy_score(y_test_classification, y_pred_classification)\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "\n",
        "conf_matrix = confusion_matrix(y_test_classification, y_pred_classification)\n",
        "print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
        "\n",
        "class_report = classification_report(y_test_classification, y_pred_classification)\n",
        "print(f\"Classification Report:\\n{class_report}\")\n",
        "\n",
        "# Get feature importances from the trained classification model\n",
        "feature_importances = classification_model.feature_importances_\n",
        "feature_names = X_train_classification.columns # Use columns from training data for feature names\n",
        "\n",
        "importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importances})\n",
        "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
        "\n",
        "print(\"\\nFeature Importance:\")\n",
        "print(importance_df)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NotFittedError",
          "evalue": "This RandomForestClassifier instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3923688674.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Assuming classification_model, X_test_classification, and y_test_classification are defined from previous steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0my_pred_classification\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassification_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_classification\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test_classification\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_classification\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m         \"\"\"\n\u001b[0;32m--> 904\u001b[0;31m         \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    905\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    942\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[0mcorresponds\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mattribute\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mterm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    943\u001b[0m         \"\"\"\n\u001b[0;32m--> 944\u001b[0;31m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    945\u001b[0m         \u001b[0;31m# Check data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m   1755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1756\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattributes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_or_any\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1757\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"name\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1758\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1759\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotFittedError\u001b[0m: This RandomForestClassifier instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13b48dbc"
      },
      "source": [
        "## Prediction on new data\n",
        "\n",
        "### Subtask:\n",
        "Use the trained Random Forest model to predict stock price increase/decrease for the period from 2023-01-01 to 2024-01-01.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8af5a55"
      },
      "source": [
        "**Reasoning**:\n",
        "Download new data, engineer features, create target variable, align dataframes, and predict using the trained classification model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "31480d76",
        "outputId": "1f924328-acf9-42cc-bb61-5fe26e700f08"
      },
      "source": [
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "\n",
        "# 1. Download historical stock price data for Apple Inc. (AAPL) from 2023-01-01 to 2024-01-01\n",
        "new_data = yf.download(\"AAPL\", start=\"2023-01-01\", end=\"2024-01-01\")\n",
        "\n",
        "# 2. Engineer the same features for new_data\n",
        "new_data['MA_5'] = new_data['Close'].rolling(window=5).mean()\n",
        "new_data['MA_10'] = new_data['Close'].rolling(window=10).mean()\n",
        "new_data['MA_50'] = new_data['Close'].rolling(window=50).mean()\n",
        "new_data['Daily_Range'] = new_data['High'] - new_data['Low']\n",
        "new_data['Daily_Return'] = new_data['Close'].pct_change()\n",
        "\n",
        "# 3. Create the features DataFrame X_new and ensure column order matches X_train_classification\n",
        "feature_names = X_train_classification.columns\n",
        "X_new = new_data[feature_names]\n",
        "\n",
        "# 4. Create the target variable y_new_classification and align with X_new by dropping NaNs\n",
        "new_data['Price_Increase'] = (new_data['Close'].shift(-1) > new_data['Close']).astype(int)\n",
        "y_new_classification = new_data['Price_Increase']\n",
        "\n",
        "# Combine X_new and y_new_classification to drop corresponding rows with NaNs\n",
        "combined_new_data = pd.concat([X_new, y_new_classification.rename('y_new_classification')], axis=1).dropna()\n",
        "\n",
        "X_new_cleaned = combined_new_data[X_new.columns]\n",
        "y_new_classification_cleaned = combined_new_data['y_new_classification']\n",
        "\n",
        "# 5. Use the trained classification_model to predict\n",
        "# Ensure the order of columns in X_new_cleaned matches the training data\n",
        "X_new_cleaned = X_new_cleaned[X_train_classification.columns] # Reindex to match training columns\n",
        "\n",
        "y_pred_new_classification = classification_model.predict(X_new_cleaned)\n",
        "\n",
        "print(\"Shape of X_new_cleaned:\", X_new_cleaned.shape)\n",
        "print(\"Shape of y_new_classification_cleaned:\", y_new_classification_cleaned.shape)\n",
        "print(\"Shape of y_pred_new_classification:\", y_pred_new_classification.shape)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2814606548.py:5: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  new_data = yf.download(\"AAPL\", start=\"2023-01-01\", end=\"2024-01-01\")\n",
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NotFittedError",
          "evalue": "This RandomForestClassifier instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2814606548.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0mX_new_cleaned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_new_cleaned\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_train_classification\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# Reindex to match training columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0my_pred_new_classification\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassification_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_new_cleaned\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Shape of X_new_cleaned:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_new_cleaned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m         \"\"\"\n\u001b[0;32m--> 904\u001b[0;31m         \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    905\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    942\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[0mcorresponds\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mattribute\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mterm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    943\u001b[0m         \"\"\"\n\u001b[0;32m--> 944\u001b[0;31m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    945\u001b[0m         \u001b[0;31m# Check data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m   1755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1756\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattributes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_or_any\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1757\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"name\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1758\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1759\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotFittedError\u001b[0m: This RandomForestClassifier instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cf87d3b"
      },
      "source": [
        "## Evaluation on new data\n",
        "\n",
        "### Subtask:\n",
        "Evaluate the performance of the Random Forest model on the 2023-2024 data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d618fbec"
      },
      "source": [
        "**Reasoning**:\n",
        "Import the necessary metrics for model evaluation and calculate the accuracy, confusion matrix, and classification report for the predictions on the new data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7a3ed910",
        "outputId": "65583eb0-78aa-42ca-b1c6-df6356953600"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "# Assuming y_new_classification_cleaned and y_pred_new_classification are defined from the previous step\n",
        "\n",
        "# Calculate accuracy on the new data\n",
        "accuracy_new = accuracy_score(y_new_classification_cleaned, y_pred_new_classification)\n",
        "print(f\"Accuracy on 2023-2024 data: {accuracy_new}\")\n",
        "\n",
        "# Generate confusion matrix on the new data\n",
        "conf_matrix_new = confusion_matrix(y_new_classification_cleaned, y_pred_new_classification)\n",
        "print(f\"Confusion Matrix on 2023-2024 data:\\n{conf_matrix_new}\")\n",
        "\n",
        "# Print classification report on the new data\n",
        "class_report_new = classification_report(y_new_classification_cleaned, y_pred_new_classification)\n",
        "print(f\"Classification Report on 2023-2024 data:\\n{class_report_new}\")"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on 2023-2024 data: 0.44776119402985076\n",
            "Confusion Matrix on 2023-2024 data:\n",
            "[[72 20]\n",
            " [91 18]]\n",
            "Classification Report on 2023-2024 data:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.44      0.78      0.56        92\n",
            "           1       0.47      0.17      0.24       109\n",
            "\n",
            "    accuracy                           0.45       201\n",
            "   macro avg       0.46      0.47      0.40       201\n",
            "weighted avg       0.46      0.45      0.39       201\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3d303a08"
      },
      "source": [
        "## Strategy discussion\n",
        "\n",
        "### Subtask:\n",
        "Discuss potential trading strategies based on the performance of the classification model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b97dfbf3"
      },
      "source": [
        "**Reasoning**:\n",
        "Based on the previous evaluation results, I will discuss potential trading strategies, acknowledge the model's limitations, and suggest next steps for improvement.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4172f5e2",
        "outputId": "20945932-cd04-4532-b648-a0883e9f6bb1"
      },
      "source": [
        "# Assuming accuracy, conf_matrix, class_report, accuracy_new, conf_matrix_new, and class_report_new are defined from previous steps\n",
        "\n",
        "print(\"Discussion on Potential Trading Strategies and Model Limitations:\")\n",
        "print(\"\\nEvaluation on Initial Test Data (up to 2023-01-01):\")\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
        "print(\"Classification Report:\\n\", class_report)\n",
        "\n",
        "print(\"\\nEvaluation on New Data (2023-2024):\")\n",
        "print(\"Accuracy on 2023-2024 data:\", accuracy_new)\n",
        "print(\"Confusion Matrix on 2023-2024 data:\\n\", conf_matrix_new)\n",
        "print(f\"Classification Report on 2023-2024 data:\\n{class_report_new}\") # Use f-string for clarity\n",
        "\n",
        "print(\"\\n--- Analysis ---\")\n",
        "print(\"The Random Forest classification model showed a moderate performance on the initial test data (up to 2023-01-01).\")\n",
        "print(\"On the initial test data:\")\n",
        "print(f\"- Accuracy: {accuracy:.2f}%\")\n",
        "print(f\"- Precision for predicting increase (Class 1): {conf_matrix[1, 1] / (conf_matrix[0, 1] + conf_matrix[1, 1]):.2f}\")\n",
        "print(f\"- Recall for predicting increase (Class 1): {conf_matrix[1, 1] / (conf_matrix[1, 0] + conf_matrix[1, 1]):.2f}\")\n",
        "print(f\"- F1-score for predicting increase (Class 1): {2 * ((conf_matrix[1, 1] / (conf_matrix[0, 1] + conf_matrix[1, 1])) * (conf_matrix[1, 1] / (conf_matrix[1, 0] + conf_matrix[1, 1]))) / ((conf_matrix[1, 1] / (conf_matrix[0, 1] + conf_matrix[1, 1])) + (conf_matrix[1, 1] / (conf_matrix[1, 0] + conf_matrix[1, 1]))):.2f}\") # Calculate F1 from confusion matrix\n",
        "print(\"\\nWhen evaluated on the new data from 2023-2024, the model's performance significantly dropped.\")\n",
        "print(\"On the 2023-2024 data:\")\n",
        "print(f\"- Accuracy: {accuracy_new:.2f}%\")\n",
        "# Add checks for division by zero before calculating precision and recall for the new data\n",
        "precision_new_class1 = conf_matrix_new[1, 1] / (conf_matrix_new[0, 1] + conf_matrix_new[1, 1]) if (conf_matrix_new[0, 1] + conf_matrix_new[1, 1]) != 0 else 0\n",
        "recall_new_class1 = conf_matrix_new[1, 1] / (conf_matrix_new[1, 0] + conf_matrix_new[1, 1]) if (conf_matrix_new[1, 0] + conf_matrix_new[1, 1]) != 0 else 0\n",
        "f1_new_class1 = 2 * (precision_new_class1 * recall_new_class1) / (precision_new_class1 + recall_new_class1) if (precision_new_class1 + recall_new_class1) != 0 else 0\n",
        "\n",
        "print(f\"- Precision for predicting increase (Class 1): {precision_new_class1:.2f}\")\n",
        "print(f\"- Recall for predicting increase (Class 1): {recall_new_class1:.2f}\")\n",
        "print(f\"- F1-score for predicting increase (Class 1): {f1_new_class1:.2f}\")\n",
        "\n",
        "print(\"\\nThis significant drop in performance on recent data highlights that the model trained on older data does not generalize well to newer market conditions. The model struggles significantly to correctly predict price increases on the new data.\")\n",
        "\n",
        "\n",
        "print(\"\\n--- Potential Trading Strategies (with extreme caution) ---\")\n",
        "print(\"Given the poor performance on recent data, relying solely on this model for trading is highly risky and not recommended. However, if one were to consider strategies based on its limited insights on the *initial* test data:\")\n",
        "print(\"\\nConservative Strategy (based on initial test data): Consider buying when the model predicts a price increase (Class 1) on data similar to the *initial* training period, but be extremely cautious as the model's ability to predict increases on new data is very low. Avoid trading when the model predicts a decrease, as it has a better recall for this class on the initial data, but still not perfect precision.\")\n",
        "print(\"\\nAggressive Strategy: This is NOT recommended given the model's poor performance on recent data. Any aggressive strategy based on this model would likely lead to significant losses.\")\n",
        "\n",
        "print(\"\\n--- Limitations and Risks ---\")\n",
        "print(\"The primary limitation is the model's inability to generalize to recent market conditions, as evidenced by the significant drop in performance on the 2023-2024 data. This suggests that the engineered features and the model trained on older data are not capturing the dynamics of the current market.\")\n",
        "print(\"The risks of using this model for real-world trading are extremely high due to its poor predictive power on recent data, particularly for price increases. Trading based on this model would likely result in significant financial losses.\")\n",
        "\n",
        "print(\"\\n--- Next Steps for Improvement ---\")\n",
        "print(\"1.  **Retrain with Recent Data:** The model must be retrained using data that includes the most recent market conditions (e.g., up to the end of 2024 or later) to see if it can learn from current trends.\")\n",
        "print(\"2.  **Advanced Feature Engineering:** Explore more advanced technical indicators, macroeconomic factors, news sentiment analysis, and alternative data sources that might be more predictive of recent price movements.\")\n",
        "print(\"3.  **Time Series Modeling:** Experiment with models specifically designed for time series data, such as ARIMA, LSTMs, or other deep learning architectures, which might be better at capturing temporal dependencies.\")\n",
        "print(\"4.  **Hyperparameter Tuning and Cross-Validation:** Perform thorough hyperparameter tuning and use time series cross-validation techniques to get a more reliable estimate of the model's performance on unseen future data.\")\n",
        "print(\"5.  **Consider Market Regimes:** Investigate if the model performs differently in different market regimes (e.g., bull vs. bear markets) and potentially build regime-specific models.\")"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Discussion on Potential Trading Strategies and Model Limitations:\n",
            "\n",
            "Evaluation on Initial Test Data (up to 2023-01-01):\n",
            "Accuracy: 0.5283018867924528\n",
            "Confusion Matrix:\n",
            " [[54 48]\n",
            " [52 58]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.53      0.52       102\n",
            "           1       0.55      0.53      0.54       110\n",
            "\n",
            "    accuracy                           0.53       212\n",
            "   macro avg       0.53      0.53      0.53       212\n",
            "weighted avg       0.53      0.53      0.53       212\n",
            "\n",
            "\n",
            "Evaluation on New Data (2023-2024):\n",
            "Accuracy on 2023-2024 data: 0.44776119402985076\n",
            "Confusion Matrix on 2023-2024 data:\n",
            " [[72 20]\n",
            " [91 18]]\n",
            "Classification Report on 2023-2024 data:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.44      0.78      0.56        92\n",
            "           1       0.47      0.17      0.24       109\n",
            "\n",
            "    accuracy                           0.45       201\n",
            "   macro avg       0.46      0.47      0.40       201\n",
            "weighted avg       0.46      0.45      0.39       201\n",
            "\n",
            "\n",
            "--- Analysis ---\n",
            "The Random Forest classification model showed a moderate performance on the initial test data (up to 2023-01-01).\n",
            "On the initial test data:\n",
            "- Accuracy: 0.53%\n",
            "- Precision for predicting increase (Class 1): 0.55\n",
            "- Recall for predicting increase (Class 1): 0.53\n",
            "- F1-score for predicting increase (Class 1): 0.54\n",
            "\n",
            "When evaluated on the new data from 2023-2024, the model's performance significantly dropped.\n",
            "On the 2023-2024 data:\n",
            "- Accuracy: 0.45%\n",
            "- Precision for predicting increase (Class 1): 0.47\n",
            "- Recall for predicting increase (Class 1): 0.17\n",
            "- F1-score for predicting increase (Class 1): 0.24\n",
            "\n",
            "This significant drop in performance on recent data highlights that the model trained on older data does not generalize well to newer market conditions. The model struggles significantly to correctly predict price increases on the new data.\n",
            "\n",
            "--- Potential Trading Strategies (with extreme caution) ---\n",
            "Given the poor performance on recent data, relying solely on this model for trading is highly risky and not recommended. However, if one were to consider strategies based on its limited insights on the *initial* test data:\n",
            "\n",
            "Conservative Strategy (based on initial test data): Consider buying when the model predicts a price increase (Class 1) on data similar to the *initial* training period, but be extremely cautious as the model's ability to predict increases on new data is very low. Avoid trading when the model predicts a decrease, as it has a better recall for this class on the initial data, but still not perfect precision.\n",
            "\n",
            "Aggressive Strategy: This is NOT recommended given the model's poor performance on recent data. Any aggressive strategy based on this model would likely lead to significant losses.\n",
            "\n",
            "--- Limitations and Risks ---\n",
            "The primary limitation is the model's inability to generalize to recent market conditions, as evidenced by the significant drop in performance on the 2023-2024 data. This suggests that the engineered features and the model trained on older data are not capturing the dynamics of the current market.\n",
            "The risks of using this model for real-world trading are extremely high due to its poor predictive power on recent data, particularly for price increases. Trading based on this model would likely result in significant financial losses.\n",
            "\n",
            "--- Next Steps for Improvement ---\n",
            "1.  **Retrain with Recent Data:** The model must be retrained using data that includes the most recent market conditions (e.g., up to the end of 2024 or later) to see if it can learn from current trends.\n",
            "2.  **Advanced Feature Engineering:** Explore more advanced technical indicators, macroeconomic factors, news sentiment analysis, and alternative data sources that might be more predictive of recent price movements.\n",
            "3.  **Time Series Modeling:** Experiment with models specifically designed for time series data, such as ARIMA, LSTMs, or other deep learning architectures, which might be better at capturing temporal dependencies.\n",
            "4.  **Hyperparameter Tuning and Cross-Validation:** Perform thorough hyperparameter tuning and use time series cross-validation techniques to get a more reliable estimate of the model's performance on unseen future data.\n",
            "5.  **Consider Market Regimes:** Investigate if the model performs differently in different market regimes (e.g., bull vs. bear markets) and potentially build regime-specific models.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5d9f1352"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   The linear regression model achieved a Mean Squared Error (MSE) of approximately 6.78 and an R-squared (R²) score of approximately 0.99 on the initial test data (up to 2023-01-01), indicating a strong fit to the training data.\n",
        "*   The Random Forest classification model showed a moderate performance on the initial test data (up to 2023-01-01) with an accuracy of approximately 52.83%. The confusion matrix and classification report indicated similar performance for both predicting price increases and decreases.\n",
        "*   Feature importance analysis for the Random Forest model on the initial data highlighted 'Daily\\_Return', 'MA\\_50', and 'Volume' as the most influential features.\n",
        "*   When evaluated on the new data from 2023-2024, the Random Forest classification model's performance significantly decreased, with an accuracy of approximately 44.8%.\n",
        "*   On the 2023-2024 data, the classification model struggled significantly with correctly predicting price increases (low recall and F1-score for class 1) but was somewhat better at identifying price decreases (higher recall for class 0, though with lower precision).\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   The significant drop in the classification model's performance on recent data (2023-2024) compared to the initial test data suggests that the model trained on older data does not generalize well to newer market conditions. This highlights the dynamic nature of financial markets and the need for models to adapt to changing trends.\n",
        "*   Given the poor performance on recent data, relying solely on this classification model for real-world trading is highly risky and not recommended. Future work should focus on retraining the model with more recent data, exploring more sophisticated features (including external factors), and potentially using more advanced modeling techniques suited for time series data to improve generalization and predictive power.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}